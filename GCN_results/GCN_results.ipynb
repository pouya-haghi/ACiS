{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determing the packet length for each rank\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "# file_name = 'GCN_matrices/Cora_A.txt'\n",
    "num_rank = 96\n",
    "def get_packetLength_per_rank(num_rank): # This is the number of elements\n",
    "    directory = 'GCN_matrices'\n",
    "    dict_packet_length = {}\n",
    "    dict_ratio = {}\n",
    "    for filenm in os.listdir(directory): # iterate over all files\n",
    "        file_name = os.path.join(directory, filenm)\n",
    "        if os.path.isfile(file_name): # if it is a file\n",
    "            splitted_file_name = file_name.split(\"/\")[1].split(\"_\")\n",
    "            dataset = splitted_file_name[0]\n",
    "#             print(file_name)\n",
    "            bucket_list = [0 for g in range(num_rank)] # total: both diagonal and off-diagonal\n",
    "            bucket_list_diagonal = [0 for g in range(num_rank)] # only diagonal\n",
    "            with open(file_name) as f:\n",
    "                line1 = f.readline() \n",
    "                line2 = int(f.readline())\n",
    "                lines = f.readlines()\n",
    "                num_row = int(line1.split()[0])\n",
    "                num_col = int(line1.split()[1])\n",
    "                bucket_length = int(num_row/num_rank)\n",
    "                for i in range(line2):\n",
    "#                     print(lines[i])\n",
    "#                     print(i)\n",
    "#                     print(row)\n",
    "                    row = int(lines[i].split()[0])\n",
    "                    col = int(lines[i].split()[1])\n",
    "                    bucket = int(row/bucket_length)\n",
    "                    if bucket > num_rank - 1: # if we are out of range as a result of rounding bucket_length \\\\\n",
    "                        # just add these outliers to the last rank\n",
    "                        bucket = num_rank - 1\n",
    "                    bucket_list[bucket] += 1\n",
    "                    if col >= bucket*bucket_length and col < (bucket +1) * bucket_length:\n",
    "                        bucket_list_diagonal[bucket] += 1\n",
    "            ratio_diag = np.array(bucket_list_diagonal)/np.array(bucket_list)\n",
    "            # ratio of diag over total (both diagonal and off-diagonal)\n",
    "            if splitted_file_name[1] == 'A.txt': # A matrix is being used for both layers\n",
    "                key1 = dataset + '_L1_AXW'\n",
    "                key2 = dataset + '_L2_AXW'\n",
    "                dict_packet_length[key1] = bucket_list\n",
    "                dict_packet_length[key2] = bucket_list\n",
    "                dict_ratio[key1] = ratio_diag\n",
    "                dict_ratio[key2] = ratio_diag\n",
    "            elif splitted_file_name[1] == 'feat': \n",
    "                if splitted_file_name[2] == 'L1.txt':\n",
    "                    key = dataset + '_L1_XW'\n",
    "                    dict_packet_length[key] = bucket_list\n",
    "                    dict_ratio[key] = ratio_diag\n",
    "                elif splitted_file_name[2] == 'L2.txt':\n",
    "                    key = dataset + '_L2_XW'\n",
    "                    dict_packet_length[key] = bucket_list\n",
    "                    dict_ratio[key] = ratio_diag\n",
    "                else:\n",
    "                    print('unsupported file name')\n",
    "            else:\n",
    "                print('unsupported file name')\n",
    "    return dict_packet_length, dict_ratio\n",
    "#     return dict_packet_length\n",
    "# print(get_packetLength_per_rank(file_name, num_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_packet_length, ratio_diag = get_packetLength_per_rank(num_rank)\n",
    "# print(dict_packet_length)\n",
    "# print('-------------------------------------------')\n",
    "# print(ratio_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constant import *\n",
    "import math\n",
    "import random as ra\n",
    "\n",
    "\n",
    "def sweep(sweep_threshold, sweep_step, payload_length, num_port):\n",
    "    # payload_length is a list and is in Bytes\n",
    "    ra.seed(1)\n",
    "    results = []\n",
    "    time_stamp = [0 for j in range(num_port)]\n",
    "    sweep_num = int(sweep_threshold/sweep_step)\n",
    "    num_expr = sweep_num ** num_port\n",
    "    verbose_freq = 100 # showing the progress for each segment\n",
    "    verbose_segment = int(num_expr/verbose_freq)\n",
    "    verbose_num = 0\n",
    "    for i in range(num_expr):\n",
    "        # print(i)\n",
    "        if i%verbose_segment == 0:\n",
    "            print(verbose_num, \" percent\")\n",
    "            verbose_num += 1\n",
    "        # print(time_stamp)\n",
    "        delay = comp_delay(time_stamp, payload_length, num_port, 'default', 0)\n",
    "        results.append(delay)\n",
    "        # print(delay)\n",
    "        time_stamp[0] += sweep_step\n",
    "        for k in range(num_port):\n",
    "            if time_stamp[k] == sweep_threshold:\n",
    "                time_stamp[k] = 0\n",
    "                if k != num_port - 1:\n",
    "                    time_stamp[k+1] += sweep_step\n",
    "    return results\n",
    "\n",
    "def sweepRand(num_expr, sweep_threshold, sweep_step, payload_length, num_port):\n",
    "    # payload_length is a list and is in Bytes\n",
    "    ra.seed(1)\n",
    "    results = []\n",
    "    sweep_num = int(sweep_threshold/sweep_step)\n",
    "    verbose_freq = 100 # showing the progress for each segment\n",
    "    verbose_segment = int(num_expr/verbose_freq)\n",
    "    verbose_num = 0\n",
    "    for i in range(num_expr):\n",
    "        # print(i)\n",
    "        if i%verbose_segment == 0:\n",
    "            print(verbose_num, \" percent\")\n",
    "            verbose_num += 1\n",
    "        # print(time_stamp)\n",
    "        # time_stamp[0] += sweep_step\n",
    "        time_stamp = [ra.randrange(0, sweep_threshold, sweep_step) for j in range(num_port)]\n",
    "        delay = comp_delay(time_stamp, payload_length, num_port, 'default', [0 for j in range(num_port)])\n",
    "        results.append(delay)\n",
    "        # print(delay)\n",
    "    print('finished')\n",
    "    return results\n",
    "\n",
    "def comp_delay(time_stamp, payload_length, num_port, op_type, inp_packet_delay):\n",
    "    # time is considered as ns\n",
    "    # time_stamp is a list\n",
    "    # payload_length is a list and is in Bytes\n",
    "    # inp_packet_delay is a list\n",
    "    mytime = 0\n",
    "    end_time_port = [0 for i in range(num_port)]\n",
    "    curr_queue = 0 # pointer to which queue\n",
    "    num_beats = [math.ceil((payload_length[k] + HEADER_LENGTH)/PHIT_SIZE) for k in range(num_port)]\n",
    "    if op_type == 'default':\n",
    "        packet_delay = [num_beats[k] * PERIOD_CLK for k in range(num_port)]\n",
    "    else:\n",
    "        packet_delay = inp_packet_delay\n",
    "    queuefinished = [False for i in range(num_port)]\n",
    "    # num_finished = 0\n",
    "    \n",
    "    while all(queuefinished) == False:\n",
    "        if mytime >= time_stamp[curr_queue] and queuefinished[curr_queue] == False: #schedule an consume the packet\n",
    "            queuefinished[curr_queue] = True\n",
    "            mytime += packet_delay[curr_queue]\n",
    "            end_time_port[curr_queue] = mytime + SWITCH_LATENCY\n",
    "            # print(\"queue id \", curr_queue, \" is finished\", \"num_queue finished is: \", num_finished, \"out of: \", num_port)\n",
    "            # num_finished += 1\n",
    "        \n",
    "        # round-robin\n",
    "        if (curr_queue == num_port - 1):\n",
    "            curr_queue = 0\n",
    "        else:\n",
    "            curr_queue += 1\n",
    "        \n",
    "        # one clock delay for checking the next queue\n",
    "        mytime += PERIOD_CLK \n",
    "    \n",
    "    end_time_global = mytime + SWITCH_LATENCY\n",
    "    return end_time_global, end_time_port\n",
    "               \n",
    "def analysis(results):\n",
    "    # print(results)\n",
    "    print('max: ', max(results))\n",
    "    print('min: ', min(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_port = 16\n",
    "# results = sweepRand(num_expr = 1000000, sweep_threshold = 100, sweep_step = 10,\n",
    "#                     payload_length = [1000 for k in range(num_port)], num_port = num_port)\n",
    "# analysis(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constant import *\n",
    "def instruction_count(instr, vlen):\n",
    "    if instr == 'vse32_v':\n",
    "        return vlen + 6\n",
    "    elif instr == 'vle32_v':\n",
    "        return vlen + 6\n",
    "    elif instr == 'vmacc_xv': # dense\n",
    "        return vlen + PE_latency\n",
    "    elif instr == 'vmacc_vx': # dense\n",
    "        return vlen + PE_latency\n",
    "    elif instr == 'spvmacc_xv': # sparse\n",
    "        #     return vlen + PE_latency # lets factor out vlen and lump it with all off-diag nnz and instead only measure the overhead\n",
    "        return 1 + PE_LATENCY # 1 is b/c of packet_length at the begining of packet\n",
    "    elif instr == 'spvmacc_vx': # spearse\n",
    "#         return vlen + PE_LATENCY # lets factor out vlen and lump it with all off-diag nnz and instead only measure the overhead\n",
    "        return 1 + PE_LATENCY # 1 is b/c of packet_length at the begining of packet   \n",
    "    elif instr == 'vstreamout_v':\n",
    "        return vlen * NUM_COL\n",
    "    elif instr == 'vsetivli':\n",
    "        return 1\n",
    "    elif instr == 'wfi':\n",
    "        return 1\n",
    "    elif (instr == 'addi' or instr == 'lui' or instr == 'add' or instr == 'bne'): # scalar\n",
    "        return 1\n",
    "    else:\n",
    "        print('unsupported instruction')\n",
    "\n",
    "def gcn_FPGA_time_cgra(instruction, packet_length, SIMD_under_utilization):\n",
    "    num_rank = len(packet_length)\n",
    "    cgra_time = [0 for i in range(num_rank)]\n",
    "    for i in range(num_rank):\n",
    "        if packet_length[i] == 0:\n",
    "            cgra_time[i] = 0 # we should bypass cgra\n",
    "        else:\n",
    "            time_instr = 0 # init to zero\n",
    "            for key in instruction:\n",
    "                instr_vlen = instruction[key][0]\n",
    "                instr_cnt = instruction[key][1] # instruction count\n",
    "                instr_name = key.split('-')[0]\n",
    "                time_instr += (instruction_count(instr_name, instr_vlen))*instr_cnt\n",
    "            cgra_time[i] = (int(packet_length[i]/(SIMD_DEGREE*SIMD_under_utilization)) + time_instr) *PERIOD_CLK *1e-9 # in ns\n",
    "    return cgra_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(d,total_rank, num_iter, TM, TK, vmacc_unroll_factor, vmacc_vlen, SIMD_under_utilization):\n",
    " \n",
    "    instruction = {'addi-0':[0, 5],\n",
    "                   'lui-0':[0, 1],\n",
    "                   'wfi-0':[0, 1],\n",
    "                   # outer loop\n",
    "                   'vsetivli-0':[0, 2*TM],\n",
    "                   'vle32_v-0':[vmacc_unroll_factor, TM],\n",
    "                   'addi-1':[0, 2*TM],\n",
    "                   'bne-0':[0, TM],\n",
    "                   'vstreamout_v-0':[vmacc_unroll_factor, TM],\n",
    "                   # inner loop\n",
    "                   'vsetivli-1':[0, 2*TM*TK],\n",
    "                   'vle32_v-1':[vmacc_vlen, TM*TK],\n",
    "                   'add-0':[0, TM*TK],\n",
    "                   'addi-2':[0, TM*TK],\n",
    "                   'bne-1':[0, TM*TK],\n",
    "                   'spvmacc_xv-0':[vmacc_vlen, TM*TK*vmacc_unroll_factor]}\n",
    "    \n",
    "    # This is the raw data, storing all of the ranks\n",
    "    my_dict_cpu_unroll = {d + '_L1_XW': [[] for i in range(3 * num_iter)],\n",
    "                          d + '_L1_AXW': [[] for i in range(3 * num_iter)],\n",
    "                          d + '_L2_XW': [[] for i in range(3 * num_iter)],\n",
    "                          d + '_L2_AXW': [[] for i in range(3 * num_iter)]}\n",
    "    \n",
    "    # This is the actual cpu result (max of all ranks)\n",
    "    my_dict_cpu = {d + '_L1_XW': [0 for i in range(num_iter)],\n",
    "                   d + '_L1_AXW': [0 for i in range(num_iter)],\n",
    "                   d + '_L2_XW': [0 for i in range(num_iter)],\n",
    "                   d + '_L2_AXW': [0 for i in range(num_iter)]}\n",
    "   \n",
    "\n",
    "    my_dict_fpga = {d + '_L1_AXW':[0 for i in range(num_iter)],\n",
    "                    d + '_L2_AXW':[0 for i in range(num_iter)]}\n",
    "    \n",
    "    DIRECTORY = './GCN_results/new_results/' + str(total_rank) + '/'\n",
    "    for filenm in os.listdir(DIRECTORY):\n",
    "        split = filenm.split('_')\n",
    "        dataset = split[1]\n",
    "        if dataset != d:\n",
    "            continue\n",
    "        layer = split[2]\n",
    "        iteration = int(split[3])\n",
    "        tot_rank = int(split[4].split('.')[0])\n",
    "        if tot_rank != total_rank:\n",
    "            continue\n",
    "        file_name = os.path.join(DIRECTORY, filenm)\n",
    "        if iteration != 1:\n",
    "            with open(file_name) as f:\n",
    "                f.readline()\n",
    "                f.readline()\n",
    "                lines = f.readlines()\n",
    "                for i in range(tot_rank): #xW\n",
    "                    split_lines = lines[i].split(\" \")\n",
    "                    rank = int(split_lines[0])\n",
    "                    tot_time = float(split_lines[2])\n",
    "                    comm_time = float(split_lines[3])\n",
    "                    comp_time = float(split_lines[4].strip())\n",
    "                    key = dataset +  '_'  + layer + '_' + 'XW'\n",
    "                    my_dict_cpu_unroll[key][(iteration - 2)].append(tot_time) # -2 b/c first valid iter is offset by 2\n",
    "                    my_dict_cpu_unroll[key][(iteration-2) + num_iter].append(comm_time)\n",
    "                    my_dict_cpu_unroll[key][(iteration-2) + num_iter*2].append(comp_time)\n",
    "                for i in range(tot_rank): #A(xW)\n",
    "                    j = i + tot_rank\n",
    "                    split_lines = lines[j].split(\" \")\n",
    "                    rank = int(split_lines[0])\n",
    "                    tot_time = float(split_lines[2])\n",
    "                    comm_time = float(split_lines[3])\n",
    "                    comp_time = float(split_lines[4].strip())\n",
    "                    key = dataset + '_' + layer + '_' + 'AXW' \n",
    "                    my_dict_cpu_unroll[key][(iteration-2)].append(tot_time) # -2 b/c the first valid iteration is 2\n",
    "                    my_dict_cpu_unroll[key][(iteration-2) + num_iter].append(comm_time)\n",
    "                    my_dict_cpu_unroll[key][(iteration-2) + num_iter*2].append(comp_time)\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    # now my_dict_cpu_unroll is ready!\n",
    "    # Lets calculate my_dict_cpu and my_dict_fpga\n",
    "    dict_packet_length, ratio_diag = get_packetLength_per_rank(total_rank) # This is the number of elements\n",
    "    for key in my_dict_cpu_unroll:\n",
    "        result_list = my_dict_cpu_unroll[key]\n",
    "        time_stamp = [[0 for h in range(total_rank)] for g in range(num_iter)]\n",
    "        for j in range(3*num_iter):\n",
    "            if key[-3:] == 'AXW': # otherwise if its XW we will not accelerate it\n",
    "                if j < num_iter: # tot time calculate max(tot_time)\n",
    "                    max_result = max(result_list[j])\n",
    "                    my_dict_cpu[key][j%num_iter] = max_result * 1000.0 # in ms\n",
    "                elif j >= num_iter and j < 2*num_iter: # comm (we get the timestamp from here)\n",
    "                    max_result = max(result_list[j])\n",
    "                    time_stamp[j%num_iter] = max_result - np.array(result_list[j]) # save time_stamp for later\n",
    "                elif j >= 2*num_iter and j < 3*num_iter: # comp\n",
    "                    this_ratio_diag = np.array(ratio_diag[key])\n",
    "                    this_packet_length = np.array(dict_packet_length[key])\n",
    "                    this_result_list = np.array(result_list[j])\n",
    "                    result_comp_eff = this_result_list * this_ratio_diag # only diagonal\n",
    "                    max_result = max(result_comp_eff * 1000.0) # in ms \n",
    "                    min_result = min(result_comp_eff * 1000.0) # in ms\n",
    "                    packet_length = this_packet_length * (1.0 - this_ratio_diag) # only off-diagonal # This is the number of elements\n",
    "    #                 time_stamp = np.array(result_list[j]) - min_result\n",
    "                    gcn_fpga_time = gcn_FPGA_time_cgra(instruction, packet_length, SIMD_under_utilization)# depends on the rank b/c different ranks have different packet length\n",
    "                    # gcn_fpga_time is a list but switch_time_global is a single time\n",
    "                    switch_time_global, switch_time_port = comp_delay(time_stamp[j%num_iter], packet_length, total_rank, 'gcn', gcn_fpga_time)\n",
    "                    tot_fpga_time = max((result_comp_eff * 1000.0) + (np.array(switch_time_port) * 1e-6)) # in ms\n",
    "                    # 1000 and 1e-6 are for converting sec to ms and ns to ms respectively\n",
    "                    my_dict_fpga[key][j%num_iter] = tot_fpga_time # ms\n",
    "    #                 if verbose == True:\n",
    "    #                     print('max comp fpga: ', max_result)\n",
    "    #                     print('min comp fpga: ', min_result)\n",
    "            else: # XW\n",
    "                if j < num_iter: # tot time calculate max(tot_time)\n",
    "                    max_result = max(result_list[j])\n",
    "                    my_dict_cpu[key][j%num_iter] = max_result * 1000.0 # in ms\n",
    "\n",
    "    # now my_dict_cpu and my_dict_fpga are ready\n",
    "    print('--------- final result -----------')\n",
    "    print('cpu results: ', my_dict_cpu)\n",
    "    print('fpga results: ', my_dict_fpga)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ranks = [12, 24, 48, 96, 144]\n",
    "TM = {'Cora': [1], 'Citeseer': [1], 'Pubmed' : [3,3,1,1,1], 'Reddit': [40,19,10,5,3]} \n",
    "TK = {'Cora': 2, 'Citeseer': 3, 'Pubmed' : 10, 'Reddit': 155}\n",
    "vmacc_unroll_factor = {'Cora': [14,7,4,2,1], 'Citeseer': [17,9,5,2,1], 'Pubmed' : [32,16,25,13,7], 'Reddit': [32,32,32,32,32]}\n",
    "vmacc_vlen = {'Cora': 1354, 'Citeseer': 1109, 'Pubmed' : 2048, 'Reddit': 1503} \n",
    "SIMD_under_utilization = {'Cora': [1,1,14/16,15/16,13/16], 'Citeseer': [1,15/16, 14/16, 1,1], 'Pubmed' : [1,1,1,1,15/16], 'Reddit': [1,1,15/16,15/16,13/16]}\n",
    "num_iter = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== RANK 12 =========================\n",
      "Cora >> Rank 12 Num Iter 5 TM 1 VUF 14 VmV 1354 SIMD 1\n",
      "Cora_L1_XW\n",
      "Cora_L1_AXW\n",
      "Cora_L2_XW\n",
      "Cora_L2_AXW\n",
      "--------- final result -----------\n",
      "cpu results:  {'Cora_L1_XW': [0.5792320000000001, 0.5826680000000001, 0.6284150000000001, 0.586771, 0.9863649999999999], 'Cora_L1_AXW': [0.364327, 0.375083, 0.371476, 0.421115, 0.419948], 'Cora_L2_XW': [0.709005, 0.730065, 0.760005, 0.745062, 0.751631], 'Cora_L2_AXW': [0.208686, 0.215598, 0.20919100000000002, 0.197624, 0.230847]}\n",
      "fpga results:  {'Cora_L1_AXW': [0.017303959127016766, 0.017144986198386742, 0.017809896780831367, 0.017337393909625458, 0.0181183799637682], 'Cora_L2_AXW': [0.009261316797238258, 0.009186246247607412, 0.009459402113070909, 0.009164797519141458, 0.00917804526319396]}\n",
      "Cora >> Rank 12 Num Iter 5 TM 1 VUF 7 VmV 1354 SIMD 1\n",
      "Cora_L1_XW\n",
      "Cora_L1_AXW\n",
      "Cora_L2_XW\n",
      "Cora_L2_AXW\n",
      "--------- final result -----------\n",
      "cpu results:  {'Cora_L1_XW': [0.5792320000000001, 0.5826680000000001, 0.6284150000000001, 0.586771, 0.9863649999999999], 'Cora_L1_AXW': [0.364327, 0.375083, 0.371476, 0.421115, 0.419948], 'Cora_L2_XW': [0.709005, 0.730065, 0.760005, 0.745062, 0.751631], 'Cora_L2_AXW': [0.208686, 0.215598, 0.20919100000000002, 0.197624, 0.230847]}\n",
      "fpga results:  {'Cora_L1_AXW': [0.017303959116236767, 0.017144986187606744, 0.01780989677005137, 0.01733739389884546, 0.018118379952988203], 'Cora_L2_AXW': [0.009261316786458258, 0.009186246236827412, 0.009459402102290909, 0.009164797508361458, 0.00917804525241396]}\n",
      "Cora >> Rank 12 Num Iter 5 TM 1 VUF 4 VmV 1354 SIMD 0.875\n"
     ]
    }
   ],
   "source": [
    "datasets = ['Cora', 'Citeseer', 'Pubmed', 'Reddit']\n",
    "for d in datasets:\n",
    "    for rank in total_ranks:\n",
    "        print('================== RANK ' + str(rank) + ' =========================')\n",
    "        if d == 'Cora':\n",
    "            for (vuf,simd) in zip(vmacc_unroll_factor['Cora'], SIMD_under_utilization['Cora']):\n",
    "                print('Cora >> Rank ' + str(rank) + ' Num Iter '\\\n",
    "                      + str(num_iter) + ' TM ' + str(TM['Cora'][0]) + ' VUF ' + str(vuf) + ' VmV ' + str(vmacc_vlen['Cora']) + ' SIMD ' + str(simd))\n",
    "                get_results(d,rank, num_iter, TM['Cora'][0], TK['Cora'], vuf, vmacc_vlen['Cora'], simd)\n",
    "        if d == 'Citeseer':\n",
    "            for (vuf,simd) in  zip(vmacc_unroll_factor['Citeseer'], SIMD_under_utilization['Citeseer']):\n",
    "                print('Citeseer >> Rank ' + str(rank) + ' Num Iter '\\\n",
    "                      + str(num_iter) + ' TM ' + str(TM['Citeseer'][0]) + ' VUF ' + str(vuf) + ' VmV ' + str(vmacc_vlen['Citeseer']) + ' SIMD ' + str(simd))\n",
    "                get_results(d,rank, num_iter, TM['Citeseer'][0], TK['Citeseer'], vuf, vmacc_vlen['Citeseer'], simd)  \n",
    "        if d == 'Pubmed':\n",
    "            for (tm, vuf,simd) in  zip(TM['Pubmed'], vmacc_unroll_factor['Pubmed'], SIMD_under_utilization['Pubmed']):\n",
    "                print('Pubmed >> Rank ' + str(rank) + ' Num Iter '\\\n",
    "                      + str(num_iter) + ' TM ' + str(tm) + ' VUF ' + str(vuf) + ' VmV ' + str(vmacc_vlen['Pubmed']) + ' SIMD ' + str(simd))\n",
    "                get_results(d,rank, num_iter, tm, TK['Pubmed'], vuf, vmacc_vlen['Pubmed'], simd)  \n",
    "        if d == 'Reddit':\n",
    "            for (tm, vuf,simd) in  zip(TM['Reddit'], vmacc_unroll_factor['Reddit'], SIMD_under_utilization['Reddit']):\n",
    "                print('Reddit >> Rank ' + str(rank) + ' Num Iter '\\\n",
    "                      + str(num_iter) + ' TM ' + str(tm) + ' VUF ' + str(vuf) + ' VmV ' + str(vmacc_vlen['Reddit']) + ' SIMD ' + str(simd))\n",
    "                get_results(d,rank, num_iter, tm, TK['Reddit'], vuf, vmacc_vlen['Reddit'], simd)  \n",
    "        print('==============================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = './GCN_results/'\n",
    "for filename in os.listdir(directory):\n",
    "    fd = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isdir(fd) and fd.split('/')[-1] != '.ipynb_checkpoints':\n",
    "        tot_rank = int(fd.split('/')[-1])\n",
    "        print(fd, tot_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
